# -*- coding: utf-8 -*-
"""
å›¾ç‰‡ä¸‹è½½æ¨¡å— - æ”¯æŒä¸¤ç§æ¨¡å¼:
1. æ™®é€šæ¨¡å¼: ä½¿ç”¨requests (é€‚åˆæ™®é€šç½‘ç«™)
2. æµè§ˆå™¨æ¨¡å¼: ä½¿ç”¨Selenium (é€‚åˆæœ‰JSé˜²æŠ¤çš„ç½‘ç«™ï¼Œå¦‚åŠ é€Ÿä¹/Cloudflare)
"""

import os
import re
import time
import json
import random
import requests
import threading
import base64
import urllib3
from urllib.parse import urlparse
from metadata_writer import write_xmp_metadata, write_description
from text_parser import build_metadata_from_item, extract_name_from_text, looks_like_person_name

# ç¦ç”¨ SSL è¯ä¹¦éªŒè¯è­¦å‘Šï¼ˆæŸäº›æ”¿åºœç½‘ç«™è¯ä¹¦é…ç½®æœ‰é—®é¢˜ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class DownloadStatus:
    """ä¸‹è½½çŠ¶æ€æšä¸¾"""
    PENDING = "pending"       # ç­‰å¾…ä¸­
    DOWNLOADING = "downloading"  # ä¸‹è½½ä¸­
    SUCCESS = "success"       # æˆåŠŸ
    FAILED = "failed"         # å¤±è´¥
    SKIPPED = "skipped"       # å·²è·³è¿‡ï¼ˆä¹‹å‰å·²ä¸‹è½½ï¼‰


# å¸¸ç”¨çš„çœŸå®æµè§ˆå™¨User-Agentåˆ—è¡¨
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
]

# æ•æ„ŸåŸŸååˆ—è¡¨ - é‡åˆ°è¿™äº›åŸŸåå¿…é¡»ä½¿ç”¨æµè§ˆå™¨æ¨¡æ‹Ÿè®¿é—®
SENSITIVE_DOMAINS = [
    '.gov.cn',      # æ”¿åºœç½‘ç«™
    '.edu.cn',      # æ•™è‚²æœºæ„
    '.mil.cn',      # å†›äº‹/æ¶‰å¯†
    '.org.cn',      # ç»„ç»‡æœºæ„
    '12371.cn',     # å…±äº§å…šå‘˜ç½‘
    'people.com.cn',# äººæ°‘ç½‘
    'xinhuanet.com' # æ–°åç½‘
]


class ImageDownloader:
    """å›¾ç‰‡ä¸‹è½½å™¨ - æ”¯æŒæ™®é€šæ¨¡å¼å’Œæµè§ˆå™¨æ¨¡å¼ï¼Œæ¨¡æ‹Ÿè‡ªç„¶æµè§ˆè¡Œä¸º"""
    
    def __init__(self, save_dir, interval_min=20, interval_max=45, timeout=30, max_retries=3, use_browser=False, downloaded_urls=None, turbo_mode=False):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        
        Args:
            save_dir: ä¿å­˜ç›®å½•
            interval_min: æœ€å°ä¸‹è½½é—´éš”ï¼ˆç§’ï¼‰
            interval_max: æœ€å¤§ä¸‹è½½é—´éš”ï¼ˆç§’ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            use_browser: æ˜¯å¦ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼ï¼ˆç”¨äºç»•è¿‡JSé˜²æŠ¤ï¼‰
            downloaded_urls: å·²ä¸‹è½½URLé›†åˆï¼ˆç”±GUIç®¡ç†ï¼‰
            turbo_mode: æé€Ÿæ¨¡å¼ï¼ˆæ— é—´éš”å¿«é€Ÿä¸‹è½½ï¼Œé€‚åˆå°æ‰¹é‡ï¼‰
        """
        self.save_dir = save_dir
        self.interval_min = interval_min
        self.interval_max = interval_max
        self.timeout = timeout
        self.max_retries = max_retries
        self.use_browser = use_browser
        self.turbo_mode = turbo_mode
        
        # ä½¿ç”¨ä¼ å…¥çš„å·²ä¸‹è½½é›†åˆï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºç©ºé›†åˆ
        self.downloaded = downloaded_urls if downloaded_urls is not None else set()
        
        self._running = False
        self._paused = False
        self._stop_flag = False
        
        # çº¿ç¨‹é”ï¼ˆç”¨äºå¤šçº¿ç¨‹å®‰å…¨ï¼‰
        self._lock = threading.Lock()
        self._progress_lock = threading.Lock()
        
        # ä¸‹è½½ç»Ÿè®¡
        self._success_count = 0
        self._fail_count = 0
        self._completed_count = 0
        
        # æµè§ˆå™¨å®ä¾‹
        self.driver = None
        
        # requests Session
        self.session = requests.Session()
        self._setup_session()
        
        # å›è°ƒå‡½æ•°
        self.on_progress = None
        self.on_complete = None
    
    def _setup_session(self):
        """é…ç½®Session"""
        user_agent = random.choice(USER_AGENTS)
        self.session.headers.update({
            'User-Agent': user_agent,
            'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        })
        # å¿½ç•¥SSLè¯ä¹¦éªŒè¯ï¼ˆæŸäº›æ”¿åºœç½‘ç«™è¯ä¹¦å¯èƒ½æœ‰é—®é¢˜ï¼‰
        self.session.verify = False
    
    def _init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨ - ä½¿ç”¨ undetected-chromedriver ç»•è¿‡åçˆ¬è™«æ£€æµ‹"""
        if self.driver is not None:
            return
        
        try:
            # ä¼˜å…ˆä½¿ç”¨ undetected-chromedriverï¼ˆæ›´å¥½çš„åæ£€æµ‹èƒ½åŠ›ï¼‰
            uc_error = None
            try:
                import undetected_chromedriver as uc
                
                options = uc.ChromeOptions()
                # ä¸ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼Œå› ä¸ºå¾ˆå¤šç½‘ç«™ä¼šæ£€æµ‹
                # options.add_argument('--headless=new')  # ç¦ç”¨æ— å¤´æ¨¡å¼ï¼
                options.add_argument('--disable-gpu')
                options.add_argument('--no-sandbox')
                options.add_argument('--disable-dev-shm-usage')
                options.add_argument('--window-size=1920,1080')
                options.add_argument('--ignore-certificate-errors')
                options.add_argument('--ignore-ssl-errors')
                # ç¦ç”¨è‡ªåŠ¨åŒ–æ ‡å¿—
                options.add_argument('--disable-blink-features=AutomationControlled')
                
                # åˆ›å»º undetected Chrome
                self.driver = uc.Chrome(options=options, use_subprocess=True)
                self.driver.set_page_load_timeout(self.timeout)
                self._is_undetected = True
                return
                
            except Exception as e:
                # ImportError æˆ–ç‰ˆæœ¬ä¸åŒ¹é…ç­‰è¿è¡Œæ—¶é”™è¯¯ï¼Œç»Ÿä¸€å›é€€åˆ°æ™®é€š Seleniumã€‚
                uc_error = e
                print(f"[è­¦å‘Š] undetected-chromedriver ä¸å¯ç”¨ï¼Œå›é€€ Selenium: {e}")
            
            # å›é€€åˆ°æ™®é€š Seleniumï¼ˆä½†æ·»åŠ æ›´å¤šåæ£€æµ‹æªæ–½ï¼‰
            from selenium import webdriver
            from selenium.webdriver.chrome.service import Service
            from selenium.webdriver.chrome.options import Options
            from webdriver_manager.chrome import ChromeDriverManager
            
            options = Options()
            # ä¸ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼ˆå®¹æ˜“è¢«æ£€æµ‹ï¼‰
            # options.add_argument('--headless=new')
            options.add_argument('--disable-gpu')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--window-size=1920,1080')
            options.add_argument('--ignore-certificate-errors')
            options.add_argument('--ignore-ssl-errors')
            # åè‡ªåŠ¨åŒ–æ£€æµ‹
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option('excludeSwitches', ['enable-automation', 'enable-logging'])
            options.add_experimental_option('useAutomationExtension', False)
            
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=options)
            self.driver.set_page_load_timeout(self.timeout)
            
            # ç§»é™¤ webdriver æ ‡å¿—
            self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    })
                '''
            })
            self._is_undetected = False
            
        except Exception as e:
            raise Exception(f"åˆå§‹åŒ–æµè§ˆå™¨å¤±è´¥: {str(e)}")
    
    def _close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            try:
                self.driver.quit()
            except Exception:
                pass
            self.driver = None
    
    def _load_progress(self):
        """åŠ è½½å·²ä¸‹è½½è®°å½•"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return set(json.load(f))
            except Exception:
                pass
        return set()
    
    def _save_progress(self):
        """ä¿å­˜ä¸‹è½½è¿›åº¦"""
        try:
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(list(self.downloaded), f, ensure_ascii=False)
        except Exception:
            pass
    
    def _sanitize_filename(self, name):
        """æ¸…ç†æ–‡ä»¶å"""
        invalid_chars = r'[<>:"/\\|?*]'
        name = re.sub(invalid_chars, '_', name)
        name = name.strip(' .')
        if len(name) > 200:
            name = name[:200]
        return name or 'unnamed'
    
    def _get_unique_filename(self, base_name, ext='.jpg'):
        """è·å–å”¯ä¸€æ–‡ä»¶å"""
        filename = self._sanitize_filename(base_name) + ext
        filepath = os.path.join(self.save_dir, filename)
        
        if not os.path.exists(filepath):
            return filepath
        
        counter = 2
        while True:
            filename = f"{self._sanitize_filename(base_name)}_{counter}{ext}"
            filepath = os.path.join(self.save_dir, filename)
            if not os.path.exists(filepath):
                return filepath
            counter += 1
    
    def _download_with_requests(self, url, save_path):
        """ä½¿ç”¨requestsä¸‹è½½"""
        headers = {'Referer': f"{urlparse(url).scheme}://{urlparse(url).netloc}/"}
        
        response = self.session.get(url, headers=headers, timeout=self.timeout, stream=True)
        response.raise_for_status()
        
        with open(save_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        
        return save_path
    
    def _download_with_browser(self, url, save_path):
        """ä½¿ç”¨æµè§ˆå™¨ä¸‹è½½ï¼ˆç»•è¿‡JSé˜²æŠ¤å¦‚Cloudflare/åŠ é€Ÿä¹ï¼‰"""
        try:
            from urllib.parse import urlparse
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            
            parsed = urlparse(url)
            base_url = f"{parsed.scheme}://{parsed.netloc}/"
            domain = parsed.netloc
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»éªŒè¯è¿‡æ­¤åŸŸå
            if not hasattr(self, '_verified_domains'):
                self._verified_domains = set()
            
            # é¦–æ¬¡è®¿é—®æ­¤åŸŸåæ—¶ï¼Œå…ˆå»é¦–é¡µé€šè¿‡ Cloudflare éªŒè¯
            if domain not in self._verified_domains:
                try:
                    self.driver.get(base_url)
                    # ç­‰å¾… Cloudflare éªŒè¯å®Œæˆï¼ˆé€šå¸¸éœ€è¦ 5-10 ç§’ï¼‰
                    time.sleep(8)
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨éªŒè¯é¡µé¢
                    page_source = self.driver.page_source.lower()
                    cloudflare_indicators = ['checking your browser', 'just a moment', 'ddos protection', 'ray id']
                    
                    retry_count = 0
                    while any(ind in page_source for ind in cloudflare_indicators) and retry_count < 6:
                        time.sleep(5)
                        page_source = self.driver.page_source.lower()
                        retry_count += 1
                    
                    self._verified_domains.add(domain)
                    
                except Exception as e:
                    # å³ä½¿é¦–é¡µè®¿é—®å¤±è´¥ï¼Œä¹Ÿç»§ç»­å°è¯•ä¸‹è½½
                    pass
            
            # è®¿é—®å›¾ç‰‡URL
            self.driver.get(url)
            time.sleep(4)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # è·å–æµè§ˆå™¨çš„cookies
            cookies = {cookie['name']: cookie['value'] for cookie in self.driver.get_cookies()}
            
            # ä½¿ç”¨å¸¦cookiesçš„requestsä¸‹è½½å›¾ç‰‡
            headers = {
                'User-Agent': self.driver.execute_script("return navigator.userAgent;"),
                'Referer': base_url,
                'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
            }
            
            response = requests.get(url, headers=headers, cookies=cookies, timeout=self.timeout, verify=False)
            
            if response.status_code == 200:
                content_type = response.headers.get('Content-Type', '')
                if 'image' in content_type or len(response.content) > 1000:
                    with open(save_path, 'wb') as f:
                        f.write(response.content)
                    return save_path
            
            # å¦‚æœç›´æ¥ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä»æµè§ˆå™¨é¡µé¢æˆªå–å›¾ç‰‡
            try:
                # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰å›¾ç‰‡
                imgs = self.driver.find_elements(By.TAG_NAME, "img")
                if imgs:
                    img_src = imgs[0].get_attribute("src")
                    if img_src:
                        if img_src.startswith("data:image"):
                            # Base64å›¾ç‰‡
                            img_data = img_src.split(",", 1)[1]
                            with open(save_path, "wb") as f:
                                f.write(base64.b64decode(img_data))
                            return save_path
                        elif img_src.startswith("http"):
                            resp = requests.get(img_src, headers=headers, cookies=cookies, 
                                              timeout=self.timeout, verify=False)
                            if resp.status_code == 200 and len(resp.content) > 500:
                                with open(save_path, "wb") as f:
                                    f.write(resp.content)
                                return save_path
            except Exception:
                pass
            
            raise Exception(f"HTTP {response.status_code}" if 'response' in dir() else "æ— æ³•è·å–å›¾ç‰‡")
            
        except Exception as e:
            raise Exception(f"æµè§ˆå™¨ä¸‹è½½å¤±è´¥: {str(e)}")


    
    def _should_use_browser(self, url):
        """æ£€æµ‹æ˜¯å¦éœ€è¦ä½¿ç”¨æµè§ˆå™¨ï¼ˆé’ˆå¯¹æ•æ„ŸåŸŸåï¼‰"""
        try:
            domain = urlparse(url).netloc.lower()
            return any(d in domain for d in SENSITIVE_DOMAINS)
        except:
            return False

    def _download_image(self, url, save_path):
        """ä¸‹è½½å•å¼ å›¾ç‰‡ - æ™ºèƒ½è·¯ç”±"""
        # 1. å†³ç­–ï¼šæ˜¯å¦éœ€è¦æµè§ˆå™¨
        # æ˜¾å¼å¼€å¯ã€æ•æ„ŸåŸŸåã€æˆ–åŒ…å«é˜²çˆ¬ç‰¹å¾
        route_to_browser = self.use_browser or self._should_use_browser(url)
        
        if route_to_browser:
            # 2. æ‡’åŠ è½½ï¼šç¡®ä¿æµè§ˆå™¨å·²å¯åŠ¨
            if self.driver is None:
                # ä½¿ç”¨çº¿ç¨‹é”é˜²æ­¢å¤šçº¿ç¨‹åŒæ—¶å¯åŠ¨æµè§ˆå™¨
                with self._lock: 
                    self._init_browser()
            return self._download_with_browser(url, save_path)
        else:
            # 3. ç›´è¿ä¸‹è½½
            return self._download_with_requests(url, save_path)
    
    def _download_single(self, item, index, total):
        """
        ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        
        Returns:
            tuple: (success: bool, item: dict, error_msg: str)
        """
        # æ£€æŸ¥åœæ­¢æ ‡å¿—
        if self._stop_flag:
            return (False, item, "å·²åœæ­¢")
        
        # ç­‰å¾…æš‚åœ
        while self._paused and not self._stop_flag:
            time.sleep(0.5)
        
        if self._stop_flag:
            return (False, item, "å·²åœæ­¢")
        
        raw_name = item.get('name', '')
        intro = item.get('intro', '')
        url = item['url']

        # å…œåº•ï¼šæŠ“å–è¡¨æ ¼é‡Œâ€œé¢˜å¤´/æ ‡é¢˜â€ç»å¸¸ä¸æ˜¯äººåï¼›ä¼˜å…ˆä»ç®€ä»‹è¯­ä¹‰æŠ½å–å§“åç”¨äºå‘½åä¸å†™å…¥å…ƒæ•°æ®
        name = str(raw_name).strip() if raw_name is not None else ''
        if name and " - " in name:
            candidate = name.split(" - ", 1)[0].strip()
            if looks_like_person_name(candidate):
                name = candidate

        intro_text = str(intro).strip() if intro else ''
        derived_name = extract_name_from_text(intro_text)
        if derived_name:
            # åªè¦ç®€ä»‹é‡Œèƒ½æ˜ç¡®æŠ½å–åˆ°å§“åï¼Œå°±ä¼˜å…ˆç”¨å®ƒï¼ˆé¢˜å¤´/å²—ä½ç»å¸¸è¯¯å¯¼ï¼‰
            if (not name) or (not intro_text.startswith(name)) or (not looks_like_person_name(name)):
                name = derived_name
                item['name'] = name
        
        # çº¿ç¨‹å®‰å…¨åœ°æ£€æŸ¥URLæ˜¯å¦å·²ä¸‹è½½
        with self._lock:
            if url in self.downloaded:
                with self._progress_lock:
                    self._completed_count += 1
                    if self.on_progress:
                        self.on_progress(self._completed_count, total, item, DownloadStatus.SKIPPED, "URLå·²ä¸‹è½½")
                return (True, item, "è·³è¿‡")
        
        # é¢„å…ˆåˆ¤æ–­ä¸‹è½½æ¨¡å¼ç”¨äºæ˜¾ç¤º
        is_stealth = self.use_browser or self._should_use_browser(url)
        mode_label = "ğŸ•µï¸ Stealth" if is_stealth else "âš¡ Turbo"

        # é€šçŸ¥å¼€å§‹ä¸‹è½½
        with self._progress_lock:
            if self.on_progress:
                self.on_progress(self._completed_count + 1, total, item, DownloadStatus.DOWNLOADING, f"[{mode_label}] ä¸‹è½½ä¸­...")
        
        success = False
        error_msg = ""
        
        for attempt in range(self.max_retries):
            try:
                # çº¿ç¨‹å®‰å…¨åœ°è·å–å”¯ä¸€æ–‡ä»¶å
                with self._lock:
                    save_path = self._get_unique_filename(name, '.jpg')
                temp_path = save_path + '.tmp'
                
                self._download_image(url, temp_path)
                
                # æ„å»ºå…ƒæ•°æ®ï¼ˆè‡ªåŠ¨ä»ç®€ä»‹æå–æ€§åˆ«ã€å¹´é¾„ã€èŒä¸šç­‰ï¼‰
                try:
                    metadata = build_metadata_from_item(item)
                    final_path = write_xmp_metadata(temp_path, metadata)
                except Exception as xmp_err:
                    print(f"[è­¦å‘Š] XMP å…ƒæ•°æ®å†™å…¥å¤±è´¥ ({name}): {xmp_err}")
                    try:
                        final_path = write_description(temp_path, intro)
                    except Exception as exif_err:
                        print(f"[è­¦å‘Š] EXIF å…ƒæ•°æ®å†™å…¥ä¹Ÿå¤±è´¥ ({name}): {exif_err}")
                        final_path = temp_path
                
                # çº¿ç¨‹å®‰å…¨åœ°é‡å‘½åæ–‡ä»¶
                with self._lock:
                    if final_path != save_path:
                        if os.path.exists(save_path):
                            os.remove(save_path)
                        os.rename(final_path, save_path)
                    elif os.path.exists(temp_path):
                        os.rename(temp_path, save_path)
                    
                    self.downloaded.add(url)
                
                success = True
                break
                
            except Exception as e:
                error_msg = str(e)
                if 'temp_path' in locals() and os.path.exists(temp_path):
                    try:
                        os.remove(temp_path)
                    except Exception:
                        pass
                
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt + random.uniform(1, 3))
        
        # æ›´æ–°è¿›åº¦
        with self._progress_lock:
            self._completed_count += 1
            if success:
                self._success_count += 1
                if self.on_progress:
                    self.on_progress(self._completed_count, total, item, DownloadStatus.SUCCESS, "ä¸‹è½½æˆåŠŸ")
            else:
                self._fail_count += 1
                if self.on_progress:
                    self.on_progress(self._completed_count, total, item, DownloadStatus.FAILED, f"å¤±è´¥: {error_msg[:50]}")
        
        return (success, item, error_msg)
    
    def download_all(self, items):
        """æ‰¹é‡ä¸‹è½½æ‰€æœ‰å›¾ç‰‡ï¼ˆé¡ºåºé˜Ÿåˆ—æ¨¡å¼ï¼Œé¿å…è§¦å‘åçˆ¬ï¼‰"""
        self._running = True
        self._stop_flag = False
        self._success_count = 0
        self._fail_count = 0
        self._completed_count = 0
        
        total = len(items)
        os.makedirs(self.save_dir, exist_ok=True)
        
        # å¦‚æœä½¿ç”¨æµè§ˆå™¨æ¨¡å¼ï¼Œåˆå§‹åŒ–æµè§ˆå™¨
        if self.use_browser:
            try:
                self._init_browser()
            except Exception as e:
                if self.on_progress:
                    self.on_progress(0, total, {}, DownloadStatus.FAILED, f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self._running = False
                if self.on_complete:
                    self.on_complete(0, 0)
                return
        
        try:
            for i, item in enumerate(items):
                if self._stop_flag:
                    break
                
                self._download_single(item, i, total)
                
                # ä¸‹è½½é—´éš”ï¼ˆæé€Ÿæ¨¡å¼æ— é—´éš”ï¼Œæ™®é€šæ¨¡å¼æœ‰é—´éš”é¿å…åçˆ¬ï¼‰
                if i < len(items) - 1 and not self._stop_flag and not self.turbo_mode:
                    actual_interval = random.uniform(self.interval_min, self.interval_max)
                    time.sleep(actual_interval)
        
        finally:
            if self.use_browser:
                self._close_browser()
            
            self._running = False
            
            if self.on_complete:
                self.on_complete(self._success_count, self._fail_count)
    
    def start(self, items):
        """åœ¨æ–°çº¿ç¨‹ä¸­å¯åŠ¨ä¸‹è½½"""
        thread = threading.Thread(target=self.download_all, args=(items,))
        thread.daemon = True
        thread.start()
        return thread
    
    def pause(self):
        self._paused = True
    
    def resume(self):
        self._paused = False
    
    def stop(self):
        self._stop_flag = True
        self._paused = False
    
    @property
    def is_running(self):
        return self._running
    
    @property
    def is_paused(self):
        return self._paused
